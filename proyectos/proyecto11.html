<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clasificación de Sentimientos en Reseñas de Películas</title>
    <link rel="stylesheet" href="../style.css"> <!-- Enlace al archivo CSS -->
    <link rel="icon" href="favicoin.png" type="image/x-icon">
</head>

<body>
    <!-- Barra de Navegación -->
    <header class="project-header">
        <h1>Clasificación de Sentimientos en Reseñas de Películas</h1>

        <nav class="navbar">
            <a href="../index.html" class="navbar-logo">INICIO</a>
            <ul class="navbar-menu">
                <li><a href="../index.html#acerca">¿QUIEN SOY?</a></li>
                <li><a href="../index.html#proyectos">PROYECTOS</a></li>
                <li><a href="../index.html#contacto">CONTACTO</a></li>
            </ul>
        </nav>

    </header>

    <main class="containerpr">


        <div class="project-details">
            <img src="proyecto11.jpg" alt="Imagen Proyecto 11" class="project-image">
            <section class="content-box">
                <h2 class="section-title">Clasificación de Sentimientos en Reseñas de Películas
                </h2>
                <p>El objetivo de este proyecto es desarrollar un sistema capaz de clasificar las reseñas de películas
                    en categorías de sentimiento, tales como positivo o negativo. Usando un conjunto de datos con miles
                    de reseñas de películas, cada una etiquetada con un sentimiento, el desafío es entrenar modelos de
                    clasificación que puedan hacer predicciones precisas sobre el sentimiento de nuevas reseñas.</p>
                <p>El conjunto de datos utilizado contiene textos de reseñas de películas, las cuales fueron
                    preprocesadas para eliminar ruido y normalizar las palabras. El preprocesamiento de los textos
                    incluyó la eliminación de palabras irrelevantes (stop words), la lematización y la tokenización. Los
                    modelos fueron entrenados usando características extraídas mediante la técnica de vectorización
                    TF-IDF y embeddings generados por BERT.</p>
            </section>


            <section class="content-box">
                <h2 class="section-title">Metodología
                </h2>
                <p>Se siguió un enfoque de varias etapas para este proyecto, que incluyó el preprocesamiento de datos,
                    la vectorización de los textos, la implementación de varios modelos de clasificación y la evaluación
                    de su rendimiento. A continuación se detallan los pasos:</p>
                <ul>
                    <li><strong>Preprocesamiento de Datos:</strong> Se utilizó un pipeline de limpieza para eliminar
                        caracteres especiales, convertir todo a minúsculas y tokenizar las palabras.</li>
                    <li><strong>Vectorización:</strong> Se usaron técnicas de TF-IDF para convertir los textos en
                        vectores numéricos que los modelos puedan procesar.</li>
                    <li><strong>Modelos de Clasificación:</strong> Se probaron varios modelos, comenzando con un modelo
                        básico de <code>Logistic Regression</code>, seguido de un modelo de <code>LGBM</code> y
                        finalmente un modelo basado en <code>BERT</code>, que fue el más avanzado.</li>
                </ul>
            </section>

            <section class="content-box">
                <h2 class="section-title">Resultados</h2>

                <p>Los resultados mostraron que, a medida que incrementábamos la complejidad del modelo, las métricas de
                    evaluación mejoraban significativamente. A continuación se muestran los resultados obtenidos para
                    los diferentes modelos evaluados:</p>
                <table>
                    <thead>
                        <tr>
                            <th>Modelo</th>
                            <th>Exactitud</th>
                            <th>F1 Score</th>
                            <th>APS</th>
                            <th>ROC AUC</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Modelo Básico - Logistic Regression</td>
                            <td>Train: 0.94, Test: 0.88</td>
                            <td>Train: 0.94, Test: 0.88</td>
                            <td>Train: 0.92, Test: 0.92</td>
                            <td>Train: 0.98, Test: 0.94</td>
                        </tr>
                        <tr>
                            <td>LGBM</td>
                            <td>Train: 0.92, Test: 0.88</td>
                            <td>Train: 0.92, Test: 0.88</td>
                            <td>Train: 0.88, Test: 0.88</td>
                            <td>Train: 0.97, Test: 0.93</td>
                        </tr>
                        <tr>
                            <td>BERT</td>
                            <td>Train: 0.90, Test: 0.87</td>
                            <td>Train: 0.90, Test: 0.85</td>
                            <td>Train: 0.89, Test: 0.89</td>
                            <td>Train: 0.96, Test: 0.93</td>
                        </tr>
                    </tbody>
                </table>
                <p>El modelo BERT proporcionó los mejores resultados en términos de AUC ROC y F1 Score, aunque LGBM
                    también presentó un rendimiento competitivo. Esto resalta la efectividad de los modelos de redes
                    neuronales para tareas de procesamiento de lenguaje natural, especialmente cuando se utilizan
                    embeddings preentrenados como los generados por BERT.</p>



            </section>

            <section class="content-box">
                <h2 class="section-title">Objetivos y Tareas del Proyecto
                </h2>
                <p>Los objetivos principales del proyecto eran:</p>
                <ul>
                    <li>Preprocesar un conjunto de reseñas de películas para obtener características útiles para la
                        clasificación.</li>
                    <li>Implementar y evaluar varios modelos de clasificación, desde enfoques más simples como regresión
                        logística hasta modelos avanzados como LGBM y BERT.</li>
                    <li>Comparar los modelos utilizando métricas como la exactitud, F1 Score, APS y ROC AUC para
                        determinar cuál ofrece el mejor rendimiento.</li>
                </ul>

                <h2>5. Fragmentos de Código</h2>
                <h3>Preprocesamiento de Texto</h3>
                <pre>
# Preprocesamiento de textos
train_processed_4 = text_preprocessing_4(df_reviews_train['review_norm'])
test_processed_4 = text_preprocessing_4(df_reviews_test['review_norm'])

# Vectorización TF-IDF
tfidf_vectorizer_4 = TfidfVectorizer(
    stop_words=stop_words, ngram_range=(1, 2), max_df=0.9, min_df=5)
train_features_4 = tfidf_vectorizer_4.fit_transform(train_processed_4)
test_features_4 = tfidf_vectorizer_4.transform(test_processed_4)

model_4 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=100)

# Entrenar el modelo
model_4.fit(train_features_4, train_target)

# Evaluar el modelo
def evaluate_model_lgbm(model, train_features, train_target, test_features, test_target):
    train_predictions = model.predict(train_features)
    test_predictions = model.predict(test_features)

    metrics = {
        'Exactitud': accuracy_score(test_target, test_predictions),
        'F1': f1_score(test_target, test_predictions),
        'APS': average_precision_score(test_target, test_predictions),
        'ROC AUC': roc_auc_score(test_target, model.predict_proba(test_features)[:, 1])
    }

    for metric, score in metrics.items():
        print(f'{metric} - Train: {accuracy_score(train_target, model.predict(train_features)):.2f}, 
        Test: {score:.2f}')
    </pre>

            </section>

            <section class="content-box">
                <h2 class="section-title">Evaluación del Modelo con BERT
                </h2>
                <pre>
                    # Cargar el tokenizer y el modelo preentrenado
                    tokenizer = 
                    transformers.BertTokenizer.from_pretrained('bert-base-uncased')
                    config = transformers.BertConfig.from_pretrained('bert-base-uncased')
                    model_9 = transformers.BertModel.from_pretrained('bert-base-uncased')
                    
                    # Definir un modelo con una capa de clasificación encima de BERT
                    class BertClassifier(nn.Module):
                        def __init__(self, bert_model, num_labels=2):
                            super(BertClassifier, self).__init__()
                            self.bert = bert_model
                            self.classifier = 
                            nn.Linear(bert_model.config.hidden_size, num_labels)
                    
                        def forward(self, input_ids, attention_mask):
                            outputs = self.bert(input_ids=input_ids, 
                            attention_mask=attention_mask)
                            cls_output = outputs.last_hidden_state[:, 0, :]
                            logits = self.classifier(cls_output)
                            return logits
                        </pre>
            </section>



            <section class="content-box">
                <h2 class="section-title">Conclusiones y Siguientes Pasos</h2>
                <p>Este proyecto demuestra que el uso de modelos avanzados como BERT para la clasificación de
                    sentimientos en textos puede superar los enfoques más tradicionales en cuanto a precisión y
                    rendimiento. El siguiente paso será experimentar con ajustes finos en los modelos BERT, como el
                    fine-tuning sobre el conjunto de datos específico, para mejorar aún más los resultados.</p>
                <p>Además, se podría explorar la posibilidad de mejorar el preprocesamiento, como el uso de técnicas de
                    Word Embeddings, para comparar su rendimiento frente a BERT. También se podría ampliar el análisis
                    con más clases de sentimiento, como "neutral" o "mixto", para hacer el modelo más robusto.</p>
            </section>



            <section class="content-box">
                <h2 class="section-title">Enlaces</h2>
                <ul>
                    <li><a href="https://github.com/melissa9608/Aprendizaje_autom-tico_para_textos"
                            target="_blank">Repositorio
                            en GitHub</a></li>
                </ul>
            </section>
        </div>
    </main>

    <!-- Sección Contacto -->
    <section id="contacto" class="contacto">
        <h2>Contacto</h2>
        <p>Puedes contactarme en <a href="mailto:melissa9608@gmail.com">melissa9608@gmail.com</a>.</p>
        <p>Explora mis proyectos en GitHub <a href="https://github.com/melissa9608">GitHub Projects</a>.</p>
        <p>Me puedes encontrar en LinkedIn <a
                href="https://www.linkedin.com/in/melissalondono-datascientist/">LinkedIn</a>.</p>
    </section>

    <footer>
        <p>&copy; 2024 Melissa Londono. Todos los derechos reservados.</p>
    </footer>

</body>

</html>